{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3243b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import random\n",
    "import numpy as np\n",
    "from bibtexparser.bibdatabase import BibDatabase\n",
    "from bibtexparser.bparser import BibTexParser\n",
    "import bibtexparser\n",
    "\n",
    "file_path = \"/mnt/c/Users/Charlotte/Nextcloud2/Uni/Masterarbeit/Fulltext screening/dataExtractionForm_v2.7_2025-12-06.xlsx\"\n",
    "\n",
    "df_DEF = pd.read_excel(file_path, sheet_name=\"DEF\")\n",
    "\n",
    "df_paper_list = pd.read_excel(file_path, sheet_name=\"Full cited-by list\")\n",
    "\n",
    "\n",
    "## Cleaning DEF\n",
    "\n",
    "df_DEF = df_DEF.transpose()\n",
    "\n",
    "# Get rid of row that contains notes\n",
    "df_DEF = df_DEF.drop(\"Unnamed: 2\")\n",
    "\n",
    "# Make Questions column names\n",
    "# new_columns = df_DEF.iloc[0].astype(str) + ' ' + df_DEF.iloc[1].astype(str)\n",
    "new_columns = df_DEF.iloc[1].astype(str)\n",
    "\n",
    "df_DEF = df_DEF.drop(df_DEF.index[[0, 1]]).reset_index(drop=True)\n",
    "df_DEF.columns = new_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1d047ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add additional purpose as own column \n",
    "column = 'Additional interpretations'\n",
    "new_column_name = 'Visually localizing lesions as part of the final tool'  # Name der neuen Spalte\n",
    "\n",
    "# Neue Spalte erstellen: \"yes\", wenn der Eintrag exakt übereinstimmt, sonst NaN (oder z. B. \"no\")\n",
    "df_DEF[new_column_name] = df_DEF[column].apply(\n",
    "    lambda x: \"yes\" if x == \"Visually localizing lesions as part of the final tool\" else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799eedd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get bibtex label\n",
    "\n",
    "def extract_label_and_doi(bib_file_path):\n",
    "    with open(bib_file_path, 'r', encoding='utf-8') as bib_file:\n",
    "        parser = BibTexParser()\n",
    "        bib_db = BibDatabase()\n",
    "        bib_db = bibtexparser.load(bib_file, parser=parser)\n",
    "\n",
    "    data = []\n",
    "    for entry in bib_db.entries:\n",
    "        label = entry['ID']\n",
    "        doi = entry.get('doi', 'No DOI found')\n",
    "        data.append({'label': label, 'doi': doi})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "bib_file_path = 'data/Fulltext screening suitable.bib'  \n",
    "df = extract_label_and_doi(bib_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_purpose = [\n",
    "       'Model (in)validation', \n",
    "       'Data (in)validation',\n",
    "       'Scientific discovery', \n",
    "       'Finding intervention targets',\n",
    "       'Visually localizing lesions as part of the final tool', \n",
    "       'Vague explainability claims']\n",
    "\n",
    "columns_feature_assumptions = [\n",
    "       'Features “used” by the model',\n",
    "       'Features statistically associated',\n",
    "       'Features causally driving the target',\n",
    "       'Features caused by the target',\n",
    "       'Features being confounded',\n",
    "       'Features acting as suppressors',\n",
    "       'Features representing outliers or reflecting distribution shifts',\n",
    "       'Salient image features, e.g. edges',\n",
    "       'Other assumptions']\n",
    "\n",
    "columns_consequences = [\n",
    "       'Model rejection, refinement or retraining', \n",
    "       'Training data (and thus model) rejection',\n",
    "       'Test data point rejection',\n",
    "       'Data cleaning, denoising, artifact removal/mitigation etc.',\n",
    "       'Independent replication due to validity concerns',\n",
    "       '“Clearing” for subsequent use or next validation stage',\n",
    "       'Followup-study to test the associational/causal role of identified features',\n",
    "       'Prospective intervention on a feature to change/improve model output',\n",
    "       'Prospective intervention on a feature to change/improve target variable in the real world',\n",
    "       'Other consequences']\n",
    "\n",
    "columns_purpose_replacement = {\n",
    "       'Model (in)validation' : \"a\", \n",
    "       'Data (in)validation': \"b\",\n",
    "       'Scientific discovery': \"c\", \n",
    "       'Finding intervention targets': \"d\",\n",
    "       'Visually localizing lesions as part of the final tool': \"e\",\n",
    "       'Vague explainability claims': \"f\",\n",
    "}\n",
    "\n",
    "columns_feature_assumptions_replacement = {\n",
    "       'Features “used” by the model' : \"a\",\n",
    "       'Features statistically associated' : \"b\",\n",
    "       'Features causally driving the target' : \"c\",\n",
    "       'Features caused by the target' : \"d\",\n",
    "       'Features being confounded' : \"e\",\n",
    "       'Features acting as suppressors' : \"f\",\n",
    "       'Features representing outliers or reflecting distribution shifts' : \"g\",\n",
    "       'Salient image features, e.g. edges' : \"h\",\n",
    "       'Other assumptions' : \"i\"}\n",
    "\n",
    "columns_consequences_replacement = {\n",
    "       'Model rejection, refinement or retraining': \"a\" ,\n",
    "       'Training data (and thus model) rejection': \"b\",\n",
    "       'Test data point rejection': \"c\",\n",
    "       'Data cleaning, denoising, artifact removal/mitigation etc.': \"d\",\n",
    "       'Independent replication due to validity concerns': \"e\",\n",
    "       '“Clearing” for subsequent use or next validation stage': \"f\",\n",
    "       'Followup-study to test the associational/causal role of identified features': \"g\",\n",
    "       'Prospective intervention on a feature to change/improve model output': \"h\",\n",
    "       'Prospective intervention on a feature to change/improve target variable in the real world': \"i\",\n",
    "       'Other consequences': \"j\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abe3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Bib data to DEF data by using the DOI\n",
    "\n",
    "# Merge the DataFrames on the 'doi' column in df and 'DOI' column in df_paper_list\n",
    "merged_df = pd.merge(df, df_paper_list[['DOI', 'EID', 'Cited by']], left_on='doi', right_on='DOI', how='left')\n",
    "\n",
    "merged_df = merged_df.sort_values(by=['Cited by'], ascending = False)\n",
    "\n",
    "merged_df = merged_df.drop(columns=['DOI', 'doi', 'Cited by'])\n",
    "\n",
    "# Add wanted data for the table from the DEF\n",
    "\n",
    "columns = ['Paper EID',\"Which XAI methods are used?\",\n",
    "                \"Which medical imaging modality is used?\",\n",
    "                \"Which anatomical regions are shown in the images?\"\n",
    "        ] + columns_purpose + columns_feature_assumptions + columns_consequences\n",
    "\n",
    "merged_df = pd.merge(merged_df, df_DEF[columns], left_on='EID', right_on='Paper EID', how='left')\n",
    "\n",
    "merged_df = merged_df.drop(columns=['Paper EID', 'EID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4493b197",
   "metadata": {},
   "source": [
    "### Preparing Claim values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a990609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing claim values with letters\n",
    "for spalte, ersatzwert in columns_purpose_replacement.items():\n",
    "    merged_df.loc[\n",
    "        (~merged_df[spalte].isin(['NR', 'N/A'])) & (~merged_df[spalte].isna()),\n",
    "        spalte\n",
    "    ] = ersatzwert\n",
    "\n",
    "for spalte, ersatzwert in columns_feature_assumptions_replacement.items():\n",
    "    merged_df.loc[\n",
    "        (~merged_df[spalte].isin(['NR', 'N/A'])) & (~merged_df[spalte].isna()),\n",
    "        spalte\n",
    "    ] = ersatzwert\n",
    "\n",
    "for spalte, ersatzwert in columns_consequences_replacement.items():\n",
    "    merged_df.loc[\n",
    "        (~merged_df[spalte].isin(['NR', 'N/A'])) & (~merged_df[spalte].isna()),\n",
    "        spalte\n",
    "    ] = ersatzwert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92012359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenführen der Spalten Purpose\n",
    "merged_df['Purpose'] = merged_df[columns_purpose].apply(\n",
    "    lambda row: ', '.join(\n",
    "        [str(value) for value in row if pd.notna(value) and value not in ['NR', 'N/A']]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "merged_df = merged_df.drop(columns=columns_purpose)\n",
    "\n",
    "# Zusammenführen der Spalten Feature assumptions\n",
    "merged_df['Feature assumptions'] = merged_df[columns_feature_assumptions].apply(\n",
    "    lambda row: ', '.join(\n",
    "        [str(value) for value in row if pd.notna(value) and value not in ['NR', 'N/A']]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "merged_df = merged_df.drop(columns=columns_feature_assumptions)\n",
    "\n",
    "# Zusammenführen der Spalten Consequences\n",
    "merged_df['Consequences'] = merged_df[columns_consequences].apply(\n",
    "    lambda row: ', '.join(\n",
    "        [str(value) for value in row if pd.notna(value) and value not in ['NR', 'N/A']]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "merged_df = merged_df.drop(columns=columns_consequences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bac50d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.rename(\n",
    "    columns={\"label\": \"Article\", \n",
    "            'Which XAI methods are used?': 'Applied XAI methods', \n",
    "            \"Which medical imaging modality is used?\": \"Imaging Modality\", \"Which parts of the body are shown in the medical image?\": \"Anatomical regions\"}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9d518fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each entry in the \"Article\" column with \"\\cite{x}\"\n",
    "merged_df['Article'] = merged_df['Article'].apply(lambda x: f\"\\\\cite{{{x}}}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9c380501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{longtable}{lllllll}\n",
      "\\toprule\n",
      "Article & Applied XAI methods & Imaging Modality & Anatomical regions & Purpose & Feature assumptions & Consequences \\\\\n",
      "\\midrule\n",
      "\\endfirsthead\n",
      "\\toprule\n",
      "Article & Applied XAI methods & Imaging Modality & Anatomical regions & Purpose & Feature assumptions & Consequences \\\\\n",
      "\\midrule\n",
      "\\endhead\n",
      "\\midrule\n",
      "\\multicolumn{7}{r}{Continued on next page} \\\\\n",
      "\\midrule\n",
      "\\endfoot\n",
      "\\bottomrule\n",
      "\\endlastfoot\n",
      "\\cite{kermany_identifying_2018} & Occlusion Sensitivity & Optical coherence tomography & Eye & a, f & a, b &  \\\\\n",
      "\\cite{ozturk_automated_2020} & Grad-CAM & x-ray & Chest & a, e & a &  \\\\\n",
      "\\cite{li_using_2020} & Grad-CAM & CT & Chest & a, f & a, b &  \\\\\n",
      "\\cite{rajpurkar_deep_2018} & CAM & x-ray & Chest & a, f & a, b, c, h &  \\\\\n",
      "\\cite{rahman_exploring_2021} & Score-CAM & x-ray & Chest & a, f & a & a \\\\\n",
      "\\cite{polsinelli_light_2020} & CAM & CT & Chest & a, b, f & a, b & b \\\\\n",
      "\\cite{gu_ca-net_2021} & Own method & Dermoscopic images, MRI & Skin, Fetal & a, f & a, b &  \\\\\n",
      "\\cite{wang_weakly-supervised_2020} & CAM & CT & Chest & a, e, f & a, b &  \\\\\n",
      "\\cite{bien_deep-learning-assisted_2018} & CAM & MRI & Knee & a & a, b & j \\\\\n",
      "\\cite{lee_deep_2017} & Occlusion Sensitivity & Optical coherence tomography & Eye & a, f & a, b &  \\\\\n",
      "\\cite{brunese_explainable_2020} & Grad-CAM & x-ray & Chest & a, e, f & a, b &  \\\\\n",
      "\\cite{signoroni_bs-net_2021} & Own method & x-ray & Chest & a, e, f & a, b, e &  \\\\\n",
      "\\cite{roy_deep_2020} & Grad-CAM & Sonographic images & Chest & e & a & j \\\\\n",
      "\\cite{mahmud_covxnet_2020} & Grad-CAM & x-ray & Chest & a, c, e, f & a, b &  \\\\\n",
      "\\cite{hosny_deep_2018} & Grad-CAM & CT & Chest & f & a, b, h &  \\\\\n",
      "\\cite{song_deep_2021} & Grad-CAM & CT & Chest & a, e, f & a, b &  \\\\\n",
      "\\cite{rahman_reliable_2020} & Score-CAM & x-ray & Chest & a, f & a & a \\\\\n",
      "\\cite{panwar_deep_2020} & Grad-CAM & x-ray, CT & Chest & a, e, f & a &  \\\\\n",
      "\\cite{wang_fully_2020} & Grad-CAM & CT & Chest & a & a, b &  \\\\\n",
      "\\cite{bustos_padchest_2020} & Grad-CAM & x-ray & Chest & a & a &  \\\\\n",
      "\\cite{lian_hierarchical_2020} & CAM & MRI & Brain & e & a, b, h &  \\\\\n",
      "\\cite{spampinato_deep_2017} & Occlusion Sensitivity & x-ray & Hand & a, c & a, b & g \\\\\n",
      "\\cite{lee_fully_2017} & Occlusion Sensitivity & x-ray & Hand & a, f & a, b & a \\\\\n",
      "\\cite{kawahara_seven-point_2019} & CAM & Dermoscopic images & Skin & a, f & a &  \\\\\n",
      "\\cite{liu_multi-modality_2018} & Occlusion Sensitivity & MRI, PET & Brain & a, f & a, b &  \\\\\n",
      "\\cite{li_diagnosis_2019} & CAM & Sonographic images & Thyroid & a & a, b &  \\\\\n",
      "\\cite{wang_predicting_2019} & Grad-CAM & CT & Chest & a, e, f & a, b, h &  \\\\\n",
      "\\cite{ghorbani_deep_2020} & SmoothGrad & Echocardiogram & Heart & a, c, e, f & a, b, c & g, i \\\\\n",
      "\\cite{wu_jcs_2021} & Grad-CAM & CT & Chest & a, f & a, b & a \\\\\n",
      "\\cite{baltruschat_comparison_2019} & Grad-CAM & x-ray & Chest & a, f & a, b, e & b \\\\\n",
      "\\cite{jin_development_2020} & Guided Grad-CAM & CT & Chest & a, c, f & a, b &  \\\\\n",
      "\\cite{hu_weakly_2020} & Integrated Gradients & CT & Chest & a, c, e & a, b & a \\\\\n",
      "\\cite{hu_weakly_2020} & CAM & NaN & NaN &  & c & a \\\\\n",
      "\\cite{ouyang_dual-sampling_2020} & Grad-CAM & CT & Chest & a, e, f & a, e & a \\\\\n",
      "\\cite{tabik_covidgr_2020} & Grad-CAM & x-ray & Chest & a, f & a, b &  \\\\\n",
      "\\cite{bai_artificial_2020} & Grad-CAM & CT & Chest & a & a, b &  \\\\\n",
      "\\cite{sitaula_attention-based_2021} & Grad-CAM & x-ray & Chest &  & a, b &  \\\\\n",
      "\\cite{pasa_efficient_2019} & Grad-CAM & x-ray & Chest & e, f & a, c &  \\\\\n",
      "\\cite{pasa_efficient_2019} & Backpropagation Saliency Maps & NaN & NaN & a, e, f & a, b, c, h & g \\\\\n",
      "\\cite{hashmi_efficient_2020} & CAM & x-ray & Chest & a, f & a, b, c &  \\\\\n",
      "\\cite{zhang_viral_2021} & Grad-CAM & x-ray & Chest & a, f & a, b &  \\\\\n",
      "\\cite{kundu_pneumonia_2021} & Grad-CAM & x-ray & Chest & a & a &  \\\\\n",
      "\\cite{bashyam_mri_2020} & Backpropagation Saliency Maps & MRI & Brain & f & a &  \\\\\n",
      "\\cite{wang_prior-attention_2020} & Grad-CAM & CT & Chest & a & b &  \\\\\n",
      "\\cite{ko_covid-19_2020} & Grad-CAM & CT & Chest & f & a, b &  \\\\\n",
      "\\cite{mu_non-invasive_2020} & Grad-CAM & PET/CT & Chest &  & a &  \\\\\n",
      "\\cite{magesh_explainable_2020} & LIME & SPECT & Brain & f & a, b, d &  \\\\\n",
      "\\cite{qiu_multimodal_2022} & SHAP & MRI & Brain & a, c, f & a, b, c &  \\\\\n",
      "\\cite{chaunzwa_deep_2021} & Grad-CAM & CT & Chest & a, f & a, b, h &  \\\\\n",
      "\\cite{choi_fully_2021} & Grad-CAM and Guided Backpropagation combined & MRI & Brain & f & a, b &  \\\\\n",
      "\\cite{qian_prospective_2021} & Grad-CAM & Sonographic images & Breast & a, e, f & a, b &  \\\\\n",
      "\\cite{alshazly_explainable_2021} & Grad-CAM & CT & Chest & a, f & a, b, h &  \\\\\n",
      "\\cite{zhou_transformer-based_2023} & Grad-CAM & x-ray & Chest & a & a, b &  \\\\\n",
      "\\cite{shen_artificial_2021} & CAM & Sonographic images & Breast & a, f & a, b &  \\\\\n",
      "\\cite{zhao_deep_2021} & Grad-CAM & CT & Chest & a, c, e, f & a, b, c, h & g \\\\\n",
      "\\cite{islam_vision_2022} & Grad-CAM & CT & Abdomen, Renal pelvis and ureter & a, f & a, b &  \\\\\n",
      "\\cite{cao_large-scale_2023} & Grad-CAM & CT & Pancreas & a, f & a, b, e &  \\\\\n",
      "\\cite{zhang_explainable_2022} & Grad-CAM & MRI & Brain & a, f & a, b, h &  \\\\\n",
      "\\cite{ieracitano_fuzzy-enhanced_2022} & Occlusion Sensitivity & x-ray & Chest & a & a, b &  \\\\\n",
      "\\cite{shamrat_alzheimernet_2023} & Grad-CAM & MRI & Brain & a, f & a &  \\\\\n",
      "\\cite{saporta_benchmarking_2022} &  Grad-CAM, Grad-CAM++, Integrated Gradients, Eigen-CAM, DeepLIFT, LRP,  Occlusion Sensitivity & x-ray & Chest & a, e, f & a, b & j \\\\\n",
      "\\cite{shamrat_high-precision_2023} & Grad-CAM & x-ray & Chest & f &  &  \\\\\n",
      "\\cite{wang_ctformer_2023} & Own method & CT & General & f & a, b, h &  \\\\\n",
      "\\cite{hu_vgg-tswinformer_2023} & Grad-CAM & MRI & Brain & c, d & a, b, c &  \\\\\n",
      "\\cite{hossain_vision_2024} & LIME & MRI & Brain & a & a, b & a \\\\\n",
      "\\cite{wang_ssd-kd_2023} & Grad-CAM & Dermoscopic images & Skin & a & a, b &  \\\\\n",
      "\\cite{yu_morphological_2023} & Integrated Gradients, Guided Backpropagation, CAM, GAN & MRI & Brain & a, e & a, b &  \\\\\n",
      "\\cite{yu_morphological_2023} & Own method & NaN & NaN & a, e & b, c & g \\\\\n",
      "\\cite{jimenez-sanchez_memory-aware_2023} & Grad-CAM & x-ray & Breast & a, f & a, b &  \\\\\n",
      "\\cite{prinzi_yolo-based_2024} & Eigen-CAM, Occlusion Sensitivity & x-ray & Breast & a, e, f & a, b, c, i &  \\\\\n",
      "\\cite{li_lvit_2024} & Grad-CAM & x-ray & Chest & a, f & a, b, h &  \\\\\n",
      "\\cite{wang_screening_2024} & Grad-CAM & MRI & Heart & a, f & a, b &  \\\\\n",
      "\\cite{wang_screening_2024} & SHAP & NaN & NaN &  & a &  \\\\\n",
      "\\cite{el-assy_novel_2024} & Grad-CAM & MRI & Brain & f & a &  \\\\\n",
      "\\cite{chen_adversarial_2024} & Backpropagation Saliency Maps & MRI & Brain & a, c, f & a, b &  \\\\\n",
      "\\end{longtable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = merged_df.to_latex(index=False, longtable = True)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =  [\"Article\", \"Applied XAI methods\", \"Imaging modality\", \"Anatomical regions\", \"Purposes\", \"Feature assumptions\", \"Suggested Consequences\"]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-claims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
