{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7848333b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106682"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all data sheets but keeping the method information\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = 'data/scopus-download-cited-by-2025-07-17' \n",
    "\n",
    "\n",
    "# Define the file pattern\n",
    "file_pattern = os.path.join(folder_path, \"scopus_*_*.csv\")\n",
    "\n",
    "# List all matching files\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "# List to hold individual DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Regular expression to extract the XAI method name from filename\n",
    "pattern = re.compile(r\"scopus_(.*?)_.*\\.csv\")\n",
    "\n",
    "for file in files:\n",
    "    match = pattern.search(os.path.basename(file))\n",
    "    if match:\n",
    "        cited_xai_method = match.group(1)\n",
    "        df = pd.read_csv(file)\n",
    "        df[\"cited_XAI_method\"] = cited_xai_method \n",
    "        df_list.append(df)\n",
    "\n",
    "# Merge all dataframes\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Remove duplicates based on 'EID' column\n",
    "\n",
    "merged_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d13b377a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81676"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates based on 'EID' column\n",
    "# Drop duplicates on all columns except 'cited-xai-method'\n",
    "df_duplicatefree = merged_df.groupby('EID').agg(\n",
    "    lambda x: ', '.join(sorted(set(x))) if x.name == 'cited_XAI_method' else x.iloc[0]\n",
    ").reset_index()\n",
    "\n",
    "df_duplicatefree.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01ef76ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                cited_XAI_method-combo  count\n",
      "0                                                  PDP  19069\n",
      "1                                     GradCAMSelvaraju  10997\n",
      "2                                             DeepSHAP  10711\n",
      "3                                            DeConvNet   8502\n",
      "4                                                 LIME   5392\n",
      "..                                                 ...    ...\n",
      "962  Anchors, DeepSHAP, GradCAMSelvaraju, GradCAMZh...      1\n",
      "963       DeConvNet, GradCAMZhou, LIME, LRP, gradcam++      1\n",
      "964  ConditionalVariableImportance, DeConvNet, Deep...      1\n",
      "965                                   BP, GBP, IG, PDP      1\n",
      "966                 BP, DeepSHAP, LIME, LRP, gradcam++      1\n",
      "\n",
      "[967 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get frequency of each unique combination\n",
    "combo_counts = df_duplicatefree['cited_XAI_method'].value_counts().reset_index()\n",
    "combo_counts.columns = ['cited_XAI_method-combo', 'count']\n",
    "print(combo_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb7840a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79753"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only English papers\n",
    "df_filtered1 = df_duplicatefree[df_duplicatefree['Language of Original Document'] == 'English']\n",
    "df_filtered1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ec5b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50632"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only articles\n",
    "df_filtered2 = df_filtered1[df_filtered1[\"Document Type\"] == \"Article\"]\n",
    "df_filtered2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c82e46a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49437"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only published articles\n",
    "df_filtered3 = df_filtered2[df_filtered2[\"Publication Stage\"] == \"Final\"]\n",
    "df_filtered3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc502e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1918/4079896128.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered3['years_ago'] = 2025 - df_filtered3['Year']\n",
      "/tmp/ipykernel_1918/4079896128.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_filtered3['citations_per_year'] = df_filtered3.apply(\n"
     ]
    }
   ],
   "source": [
    "# Calculate citations per year\n",
    "\n",
    "df_filtered3['years_ago'] = 2025 - df_filtered3['Year']\n",
    "\n",
    "df_filtered3['citations_per_year'] = df_filtered3.apply(\n",
    "    lambda row: row['Cited by'] if row['years_ago'] <= 0 else row['Cited by'] / row['years_ago'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd6a6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "df_filtered3.to_csv('data/scopus-download-cited-by-2025-07-17/merged_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0afdea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered3 = pd.read_csv('data/scopus-download-cited-by-2025-07-17/merged_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1706616e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1918/2267538697.py:27: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  mask = df_filtered3['Title'].str.contains(pattern, flags=re.IGNORECASE, regex=True) | \\\n",
      "/tmp/ipykernel_1918/2267538697.py:28: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_filtered3['Abstract'].str.contains(pattern, flags=re.IGNORECASE, regex=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering with keywords in both Title and Abstract \n",
    "\n",
    "# Keywords should limit to the medical field\n",
    "# And limit to imaging field, i.e. avoiding biomarkers\n",
    "\n",
    "\n",
    "# Keywords Core Imaging Modalities, results: 2981\n",
    "# keywords = [\"x-ray\", \"x-rays\", \"ct\", \"mri\", \"pet\", \"spect\", \"ultrasound\"]\n",
    "\n",
    "# Keywords main methods with full names, results: 3309\n",
    "# keywords = [\"x-ray\", \"x-rays\", \"ct\", \"mri\", \"pet\", \"spect\", \"ultrasound\", \"computed tomography\", \"magnetic resonance imaging\", \"Positron Emission Tomography\", \"Single-Photon Emission Computed Tomography\"]\n",
    "\n",
    "\n",
    "# Keywords including Specialized or Derived Imaging Techniques, results: 3897\n",
    "# keywords = [\"ct\", \"tomography\", \"x-ray\", \"x-rays\", \"radiographs\", \"radiology\", \"mri\", \"magnetic resonance imaging\", \"pet\", \"spect\", \"fmri\",\"ultrasound\", \"sonography\" \"mammography\", \"scintigraphy\", \"fluoroscopy\", \"histopathology\", \"ophthalmology\", \"Ultrasonography\", \"Elastography\", \"Scintigraphy\", \"scint\", \"echocardiogram\", \"fundus photography\", \"oct\", \"dermoscopy\", \"endoscopy\"]\n",
    "\n",
    "# Radlex keywords\n",
    "# keywords = [\"fluoroscopy\", \"magnetic resonance imaging\", \"mri\", \"spectroscopy\", \"nuclear medicine imaging\", \"panographic radiograph\", \"projection radiography\", \"spectroscopy\", \"tomography\", \"ct\", \"ultrasound\"]\n",
    "\n",
    "# Test single keywords\n",
    "keywords = [\"Fundoscopy\"]\n",
    "\n",
    "# Full matching only (not part of a word)\n",
    "# \\b means space, punctuation, or the start/end of a string\n",
    "pattern = r\"\\b(\" + \"|\".join(keywords) + r\")\\b\"\n",
    "\n",
    "mask = df_filtered3['Title'].str.contains(pattern, flags=re.IGNORECASE, regex=True) | \\\n",
    "       df_filtered3['Abstract'].str.contains(pattern, flags=re.IGNORECASE, regex=True)\n",
    "\n",
    "\n",
    "df_keywordFiltered = df_filtered3[mask]\n",
    "df_keywordFiltered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86396212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_citedLim = df_keywordFiltered[df_keywordFiltered[\"citations_per_year\"] > 10]\n",
    "\n",
    "df_filtered_citedLim.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai-claims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
